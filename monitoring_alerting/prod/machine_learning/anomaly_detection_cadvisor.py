import os
import time
import logging
import requests
import pandas as pd
from sklearn.ensemble import IsolationForest
from prometheus_client import CollectorRegistry, Gauge, push_to_gateway

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')

# Environment Variables
PROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')
PUSHGATEWAY_URL = os.getenv('PUSHGATEWAY_URL', 'http://pushgateway:9091')

# Anomaly Detection Parameters
CONTAMINATION = float(os.getenv('ANOMALY_CONTAMINATION', '0.01'))
LOOKBACK_SECONDS = int(os.getenv('ANOMALY_LOOKBACK', '3600'))  # 1 hour
STEP = os.getenv('ANOMALY_STEP', '60s')  # 1 minute

# List of cAdvisor Metrics for Anomaly Detection
CADVISOR_METRICS = [
    # CPU Metrics
    'container_cpu_usage_seconds_total',
    'container_cpu_cfs_throttled_seconds_total',
    'container_cpu_cfs_periods_total',

    # Memory Metrics
    'container_memory_usage_bytes',
    'container_memory_working_set_bytes',
    'container_memory_cache',

    # Disk I/O Metrics
    'container_fs_reads_bytes_total',
    'container_fs_writes_bytes_total',
    'container_fs_usage_bytes',

    # Network Metrics
    'container_network_receive_bytes_total',
    'container_network_transmit_bytes_total',
    'container_network_receive_packets_total',
    'container_network_transmit_packets_total',

    # Process Metrics
    'container_processes',

    # Container Lifecycle Metrics
    'container_start_time_seconds'
]

def fetch_prometheus_data(query, start_time, end_time, step):
    """
    Fetch time series data from Prometheus for a given query.
    """
    try:
        response = requests.get(f"{PROMETHEUS_URL}/api/v1/query_range", params={
            'query': query,
            'start': start_time,
            'end': end_time,
            'step': step
        }, timeout=10)
        response.raise_for_status()
        data = response.json()
        if data['status'] != 'success':
            logging.error(f"Prometheus query failed for {query}: {data}")
            return []
        return data['data']['result']
    except Exception as e:
        logging.exception(f"Error fetching data from Prometheus for {query}")
        return []

def compute_anomaly_score(series_df):
    """
    Compute anomaly score using IsolationForest on a given DataFrame of values.
    """
    if series_df.empty or series_df['value'].isnull().all():
        logging.warning("Empty or invalid dataframe, returning neutral anomaly score.")
        return 0.5
    try:
        df_clean = series_df.copy()
        df_clean['value'] = df_clean['value'].ffill().fillna(0)  # Fill missing values
        model = IsolationForest(contamination=CONTAMINATION, random_state=42)
        model.fit(df_clean[['value']])
        scores = model.decision_function(df_clean[['value']])
        # Normalize anomaly score between 0 and 1
        anomaly_score = 1 - (scores[-1] + 1) / 2
        # Clamp the score between 0 and 1
        anomaly_score = max(0.0, min(1.0, anomaly_score))
        logging.debug(f"Anomaly score computed: {anomaly_score}")
        return anomaly_score
    except Exception as e:
        logging.exception("Error during anomaly score computation with IsolationForest")
        return 0.5  # Return a neutral score in case of failure

def process_labels(labels, default_metric='unknown_metric'):
    """
    Process labels by removing '__name__' and adding 'metric' label.
    If no labels remain, add a default 'metric' label.
    """
    labels = {k: v for k, v in labels.items() if k != '__name__'}

    if '__name__' in labels:
        labels['metric'] = labels.pop('__name__')

    if not labels:
        labels = {'metric': default_metric}

    return labels

def push_anomaly_score(score, labels):
    """
    Push the anomaly score to the Pushgateway with appropriate labels.
    """
    try:
        labels = process_labels(labels, default_metric='container_cpu_usage_seconds_total')  # Default metric label
        registry = CollectorRegistry()
        g = Gauge('anomaly_score', 'Anomaly score generated by ML', labelnames=labels.keys(), registry=registry)
        g.labels(**labels).set(score)
        push_to_gateway(PUSHGATEWAY_URL, job='cadvisor_anomaly', registry=registry)
        logging.info(f"Pushed anomaly score {score} with labels {labels}")
    except Exception as e:
        logging.exception("Error pushing anomaly score to Pushgateway")

def main():
    """
    Main function to iterate over all cAdvisor metrics, compute anomaly scores, and push results.
    """
    end_time = int(time.time())
    start_time = end_time - LOOKBACK_SECONDS

    for metric in CADVISOR_METRICS:
        logging.info(f"Processing metric for anomaly detection: {metric}")
        results = fetch_prometheus_data(metric, start_time, end_time, STEP)

        if not results:
            push_anomaly_score(0.5, {'metric': metric})
            continue

        for ts in results:
            values = ts['values']
            metric_labels = ts.get('metric', {})
            # Convert timestamps to datetime
            df = pd.DataFrame(values, columns=['timestamp', 'value'])
            df['value'] = pd.to_numeric(df['value'], errors='coerce')

            anomaly_score = compute_anomaly_score(df)
            push_anomaly_score(anomaly_score, metric_labels)

if __name__ == "__main__":
    main()