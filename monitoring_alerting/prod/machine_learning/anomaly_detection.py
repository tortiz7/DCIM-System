# anomaly_detection.py
import os
import time
import logging
import requests
import pandas as pd
from sklearn.ensemble import IsolationForest
from prometheus_client import CollectorRegistry, Gauge, push_to_gateway

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')

# Environment Variables
PROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://prometheus:9090')
PUSHGATEWAY_URL = os.getenv('PUSHGATEWAY_URL', 'http://pushgateway:9091')

# Anomaly Detection Parameters
CONTAMINATION = float(os.getenv('ANOMALY_CONTAMINATION', '0.01'))
LOOKBACK_SECONDS = int(os.getenv('ANOMALY_LOOKBACK', '3600'))  # 1 hour
STEP = os.getenv('ANOMALY_STEP', '60s')  # 1 minute

# List of Metrics for Anomaly Detection
ANOMALY_METRICS = [
    # CPU Metrics
    'node_cpu_seconds_total',
    'node_schedstat_running_seconds_total',

    # Memory Metrics
    'node_memory_MemTotal_bytes',
    'node_memory_MemAvailable_bytes',
    'node_memory_Cached_bytes',
    'node_memory_Buffers_bytes',
    'node_pressure_memory_waiting_seconds_total',

    # Disk I/O Metrics
    'node_disk_read_bytes_total',
    'node_disk_written_bytes_total',
    'node_disk_io_time_seconds_total',

    # Network Metrics
    'node_network_receive_bytes_total',
    'node_network_transmit_bytes_total',
    'node_network_receive_errs_total',
    'node_network_transmit_errs_total',

    # System Load Metrics
    'node_load1',
    'node_load5',
    'node_load15',

    # Process and Application Metrics
    'process_cpu_seconds_total',
    'process_resident_memory_bytes',
    'go_gc_duration_seconds',
    'go_goroutines',

    # Additional Useful Metrics
    'node_procs_running',
    'node_procs_blocked',
    'node_pressure_io_waiting_seconds_total',
    'node_nf_conntrack_entries',

    # Error and Success Metrics
    # 'node_scrape_collector_success',
    # Replace with actual metric names if available
    # 'node_netstat_tcp_errors',
    # 'node_netstat_udp_errors',
    # 'node_textfile_scrape_error'
]

def fetch_prometheus_data(query, start_time, end_time, step):
    """
    Fetch time series data from Prometheus for a given query.
    """
    try:
        response = requests.get(f"{PROMETHEUS_URL}/api/v1/query_range", params={
            'query': query,
            'start': start_time,
            'end': end_time,
            'step': step
        }, timeout=10)
        response.raise_for_status()
        data = response.json()
        if data['status'] != 'success':
            logging.error(f"Prometheus query failed for {query}: {data}")
            return []
        return data['data']['result']
    except Exception as e:
        logging.exception(f"Error fetching data from Prometheus for {query}")
        return []

def compute_anomaly_score(series_df):
    """
    Compute anomaly score using IsolationForest on a given DataFrame of values.
    """
    if series_df.empty or series_df['value'].isnull().all():
        logging.warning("Empty or invalid dataframe, returning neutral anomaly score.")
        return 0.5
    try:
        df_clean = series_df.copy()
        df_clean['value'] = df_clean['value'].ffill().fillna(0)  # Updated fillna usage
        model = IsolationForest(contamination=CONTAMINATION, random_state=42)
        model.fit(df_clean[['value']])
        scores = model.decision_function(df_clean[['value']])
        # Normalize anomaly score between 0 and 1
        anomaly_score = 1 - (scores[-1] + 1) / 2
        # Clamp the score between 0 and 1
        anomaly_score = max(0.0, min(1.0, anomaly_score))
        logging.debug(f"Anomaly score computed: {anomaly_score}")
        return anomaly_score
    except Exception as e:
        logging.exception("Error during anomaly score computation with IsolationForest")
        return 0.5  # Return a neutral score in case of failure

def process_labels(labels, default_metric='unknown_metric'):
    """
    Process labels by removing '__name__' and adding 'metric' label.
    If no labels remain, add a default 'metric' label.
    """
    # Remove '__name__'
    labels = {k: v for k, v in labels.items() if k != '__name__'}

    # Add 'metric' label if '__name__' was present
    if '__name__' in labels:
        labels['metric'] = labels.pop('__name__')

    # If no labels remain, add a default 'metric' label
    if not labels:
        labels = {'metric': default_metric}

    return labels

def push_anomaly_score(score, labels):
    """
    Push the anomaly score to the Pushgateway with appropriate labels.
    """
    try:
        labels = process_labels(labels, default_metric='node_load1')  # Replace with appropriate default if needed

        registry = CollectorRegistry()
        g = Gauge('anomaly_score', 'Anomaly score generated by ML', labelnames=labels.keys(), registry=registry)
        g.labels(**labels).set(score)
        push_to_gateway(PUSHGATEWAY_URL, job='ml_anomaly', registry=registry)
        logging.info(f"Pushed anomaly score {score} with labels {labels}")
    except Exception as e:
        logging.exception("Error pushing anomaly score to Pushgateway")

def main():
    """
    Main function to iterate over all anomaly detection metrics, compute anomaly scores, and push results.
    """
    end_time = int(time.time())
    start_time = end_time - LOOKBACK_SECONDS

    for metric in ANOMALY_METRICS:
        logging.info(f"Processing metric for anomaly detection: {metric}")
        results = fetch_prometheus_data(metric, start_time, end_time, STEP)

        if not results:
            push_anomaly_score(0.5, {'metric': metric})
            continue

        for ts in results:
            values = ts['values']
            metric_labels = ts.get('metric', {})
            # Convert timestamp to datetime
            df = pd.DataFrame(values, columns=['timestamp', 'value'])
            df['value'] = pd.to_numeric(df['value'], errors='coerce')

            anomaly_score = compute_anomaly_score(df)
            push_anomaly_score(anomaly_score, metric_labels)

if __name__ == "__main__":
    main()