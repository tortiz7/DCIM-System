FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04

ENV PYTHONUNBUFFERED=1
ENV DEBIAN_FRONTEND=noninteractive

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3-pip \
    build-essential \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

ARG CHATBOT_REPO=git@github.com:tortiz7/DCIM-System.git
ARG CHATBOT_BRANCH=chatbot-TOrtiz

RUN echo "Repo: $CHATBOT_REPO" && echo "Branch: $CHATBOT_BRANCH"

RUN mkdir -p ~/.ssh && \
    ssh-keyscan github.com >> ~/.ssh/known_hosts && \
    chmod 600 ~/.ssh/known_hosts

RUN --mount=type=ssh git clone --branch $CHATBOT_BRANCH $CHATBOT_REPO .

WORKDIR /app/ralph_chatbot

# Install Python dependencies including Unsloth
RUN pip3 install --no-cache-dir -r requirements.txt && \
    pip3 install unsloth==2024.11.10 && \
    pip3 install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes

# Verify CUDA and set up environment
RUN python3 -c "import torch; assert torch.cuda.is_available(), 'CUDA not available'; print(f'CUDA available: {torch.cuda.get_device_name(0)}')"

ENV PYTHONPATH=/app
ENV DJANGO_SETTINGS_MODULE=chatbot.settings
ENV NVIDIA_VISIBLE_DEVICES=all
ENV CUDA_VISIBLE_DEVICES=0
ENV MODEL_PATH=/app/ralph_chatbot/chatbot/model
ENV LORA_PATH=/app/ralph_chatbot/chatbot/model/adapters

# Add model verification on startup
RUN chmod +x chatbot/utils/verify_model.py

# Collect static files
RUN python3 manage.py collectstatic --noinput

ARG DOCKER_BUILDKIT=1
ARG SKIP_HEALTHCHECK=true
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD if [ "$SKIP_HEALTHCHECK" = "true" ]; then exit 0; else curl -f http://localhost:8001/health/ || exit 1; fi

EXPOSE 8001 9100

CMD ["gunicorn", \
     "--bind", "0.0.0.0:8001", \
     "--workers", "4", \
     "--timeout", "120", \
     "--keep-alive", "65", \
     "--log-level", "info", \
     "--access-logfile", "-", \
     "--error-logfile", "-", \
     "chatbot.wsgi:application"]