FROM nvidia/cuda:12.4.0-devel-ubuntu22.04

ENV PYTHONUNBUFFERED=1
ENV DEBIAN_FRONTEND=noninteractive

ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

RUN apt-get update && apt-get install -y \
    python3-pip python3-dev build-essential git curl ninja-build \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app
ENV PYTHONPATH=/app/ralph_chatbot

# SSH git clone setup
ARG CHATBOT_REPO=git@github.com:tortiz7/DCIM-System.git
ARG CHATBOT_BRANCH=chatbot-TOrtiz

RUN mkdir -p ~/.ssh && \
    ssh-keyscan github.com >> ~/.ssh/known_hosts && \
    chmod 600 ~/.ssh/known_hosts

RUN --mount=type=ssh git clone --branch $CHATBOT_BRANCH $CHATBOT_REPO .

WORKDIR /app/ralph_chatbot

# Install Python dependencies
RUN pip3 install --no-cache-dir -r requirements.txt \
    && pip3 install --no-cache-dir packaging ninja einops bitsandbytes \
    && TORCH_CUDA_ARCH_LIST="7.5" pip3 install --no-cache-dir flash-attn==1.0.9 xformers trl peft accelerate unsloth==2024.11.10

# Verify CUDA and PyTorch
RUN python3 -c "import torch; assert torch.cuda.is_available(), 'CUDA not available'; print(f'CUDA available: {torch.cuda.get_device_name(0)}')"

ENV DJANGO_SETTINGS_MODULE=chatbot.settings
ENV NVIDIA_VISIBLE_DEVICES=all
ENV CUDA_VISIBLE_DEVICES=0
ENV MODEL_PATH=/app/ralph_chatbot/chatbot/model
ENV LORA_PATH=/app/ralph_chatbot/chatbot/model/adapters

RUN chmod +x chatbot/utils/verify_model.py
RUN python3 manage.py collectstatic --noinput

# Healthcheck
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8001/health/ || exit 1

EXPOSE 8001 9100

CMD ["gunicorn", "--bind", "0.0.0.0:8001", "--workers", "4", "--timeout", "120", "--keep-alive", "65", "--log-level", "info", "--access-logfile", "-", "--error-logfile", "-", "chatbot.wsgi:application"]
